{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze the elementry classification problem - breast cancer detection UCI\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcData = pd.read_csv('/home/anshul/anaconda3/anshul/scikit-learn/Datasets/BreastCancer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>HOMA</th>\n",
       "      <th>Leptin</th>\n",
       "      <th>Adiponectin</th>\n",
       "      <th>Resistin</th>\n",
       "      <th>MCP.1</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>70</td>\n",
       "      <td>2.707</td>\n",
       "      <td>0.467409</td>\n",
       "      <td>8.8071</td>\n",
       "      <td>9.702400</td>\n",
       "      <td>7.99585</td>\n",
       "      <td>417.114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>20.690495</td>\n",
       "      <td>92</td>\n",
       "      <td>3.115</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>8.8438</td>\n",
       "      <td>5.429285</td>\n",
       "      <td>4.06405</td>\n",
       "      <td>468.786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>23.124670</td>\n",
       "      <td>91</td>\n",
       "      <td>4.498</td>\n",
       "      <td>1.009651</td>\n",
       "      <td>17.9393</td>\n",
       "      <td>22.432040</td>\n",
       "      <td>9.27715</td>\n",
       "      <td>554.697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>21.367521</td>\n",
       "      <td>77</td>\n",
       "      <td>3.226</td>\n",
       "      <td>0.612725</td>\n",
       "      <td>9.8827</td>\n",
       "      <td>7.169560</td>\n",
       "      <td>12.76600</td>\n",
       "      <td>928.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>92</td>\n",
       "      <td>3.549</td>\n",
       "      <td>0.805386</td>\n",
       "      <td>6.6994</td>\n",
       "      <td>4.819240</td>\n",
       "      <td>10.57635</td>\n",
       "      <td>773.920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age        BMI  Glucose  Insulin      HOMA   Leptin  Adiponectin  Resistin  \\\n",
       "0   48  23.500000       70    2.707  0.467409   8.8071     9.702400   7.99585   \n",
       "1   83  20.690495       92    3.115  0.706897   8.8438     5.429285   4.06405   \n",
       "2   82  23.124670       91    4.498  1.009651  17.9393    22.432040   9.27715   \n",
       "3   68  21.367521       77    3.226  0.612725   9.8827     7.169560  12.76600   \n",
       "4   86  21.111111       92    3.549  0.805386   6.6994     4.819240  10.57635   \n",
       "\n",
       "     MCP.1  Classification  \n",
       "0  417.114               1  \n",
       "1  468.786               1  \n",
       "2  554.697               1  \n",
       "3  928.220               1  \n",
       "4  773.920               1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srcData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>HOMA</th>\n",
       "      <th>Leptin</th>\n",
       "      <th>Adiponectin</th>\n",
       "      <th>Resistin</th>\n",
       "      <th>MCP.1</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>70</td>\n",
       "      <td>2.707</td>\n",
       "      <td>0.467409</td>\n",
       "      <td>8.8071</td>\n",
       "      <td>9.702400</td>\n",
       "      <td>7.99585</td>\n",
       "      <td>417.114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>20.690495</td>\n",
       "      <td>92</td>\n",
       "      <td>3.115</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>8.8438</td>\n",
       "      <td>5.429285</td>\n",
       "      <td>4.06405</td>\n",
       "      <td>468.786</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>23.124670</td>\n",
       "      <td>91</td>\n",
       "      <td>4.498</td>\n",
       "      <td>1.009651</td>\n",
       "      <td>17.9393</td>\n",
       "      <td>22.432040</td>\n",
       "      <td>9.27715</td>\n",
       "      <td>554.697</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>21.367521</td>\n",
       "      <td>77</td>\n",
       "      <td>3.226</td>\n",
       "      <td>0.612725</td>\n",
       "      <td>9.8827</td>\n",
       "      <td>7.169560</td>\n",
       "      <td>12.76600</td>\n",
       "      <td>928.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>92</td>\n",
       "      <td>3.549</td>\n",
       "      <td>0.805386</td>\n",
       "      <td>6.6994</td>\n",
       "      <td>4.819240</td>\n",
       "      <td>10.57635</td>\n",
       "      <td>773.920</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49</td>\n",
       "      <td>22.854458</td>\n",
       "      <td>92</td>\n",
       "      <td>3.226</td>\n",
       "      <td>0.732087</td>\n",
       "      <td>6.8317</td>\n",
       "      <td>13.679750</td>\n",
       "      <td>10.31760</td>\n",
       "      <td>530.410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>89</td>\n",
       "      <td>22.700000</td>\n",
       "      <td>77</td>\n",
       "      <td>4.690</td>\n",
       "      <td>0.890787</td>\n",
       "      <td>6.9640</td>\n",
       "      <td>5.589865</td>\n",
       "      <td>12.93610</td>\n",
       "      <td>1256.083</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>76</td>\n",
       "      <td>23.800000</td>\n",
       "      <td>118</td>\n",
       "      <td>6.470</td>\n",
       "      <td>1.883201</td>\n",
       "      <td>4.3110</td>\n",
       "      <td>13.251320</td>\n",
       "      <td>5.10420</td>\n",
       "      <td>280.694</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>73</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>97</td>\n",
       "      <td>3.350</td>\n",
       "      <td>0.801543</td>\n",
       "      <td>4.4700</td>\n",
       "      <td>10.358725</td>\n",
       "      <td>6.28445</td>\n",
       "      <td>136.855</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>75</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>83</td>\n",
       "      <td>4.952</td>\n",
       "      <td>1.013839</td>\n",
       "      <td>17.1270</td>\n",
       "      <td>11.578990</td>\n",
       "      <td>7.09130</td>\n",
       "      <td>318.302</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>34</td>\n",
       "      <td>21.470000</td>\n",
       "      <td>78</td>\n",
       "      <td>3.469</td>\n",
       "      <td>0.667436</td>\n",
       "      <td>14.5700</td>\n",
       "      <td>13.110000</td>\n",
       "      <td>6.92000</td>\n",
       "      <td>354.600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>29</td>\n",
       "      <td>23.010000</td>\n",
       "      <td>82</td>\n",
       "      <td>5.663</td>\n",
       "      <td>1.145436</td>\n",
       "      <td>35.5900</td>\n",
       "      <td>26.720000</td>\n",
       "      <td>4.58000</td>\n",
       "      <td>174.800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25</td>\n",
       "      <td>22.860000</td>\n",
       "      <td>82</td>\n",
       "      <td>4.090</td>\n",
       "      <td>0.827271</td>\n",
       "      <td>20.4500</td>\n",
       "      <td>23.670000</td>\n",
       "      <td>5.14000</td>\n",
       "      <td>313.730</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>24</td>\n",
       "      <td>18.670000</td>\n",
       "      <td>88</td>\n",
       "      <td>6.107</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>8.8800</td>\n",
       "      <td>36.060000</td>\n",
       "      <td>6.85000</td>\n",
       "      <td>632.220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>38</td>\n",
       "      <td>23.340000</td>\n",
       "      <td>75</td>\n",
       "      <td>5.782</td>\n",
       "      <td>1.069670</td>\n",
       "      <td>15.2600</td>\n",
       "      <td>17.950000</td>\n",
       "      <td>9.35000</td>\n",
       "      <td>165.020</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>44</td>\n",
       "      <td>20.760000</td>\n",
       "      <td>86</td>\n",
       "      <td>7.553</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>14.0900</td>\n",
       "      <td>20.320000</td>\n",
       "      <td>7.64000</td>\n",
       "      <td>63.610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>47</td>\n",
       "      <td>22.030000</td>\n",
       "      <td>84</td>\n",
       "      <td>2.869</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>26.6500</td>\n",
       "      <td>38.040000</td>\n",
       "      <td>3.32000</td>\n",
       "      <td>191.720</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>61</td>\n",
       "      <td>32.038959</td>\n",
       "      <td>85</td>\n",
       "      <td>18.077</td>\n",
       "      <td>3.790144</td>\n",
       "      <td>30.7729</td>\n",
       "      <td>7.780255</td>\n",
       "      <td>13.68392</td>\n",
       "      <td>444.395</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>64</td>\n",
       "      <td>34.529723</td>\n",
       "      <td>95</td>\n",
       "      <td>4.427</td>\n",
       "      <td>1.037394</td>\n",
       "      <td>21.2117</td>\n",
       "      <td>5.462620</td>\n",
       "      <td>6.70188</td>\n",
       "      <td>252.449</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32</td>\n",
       "      <td>36.512637</td>\n",
       "      <td>87</td>\n",
       "      <td>14.026</td>\n",
       "      <td>3.009980</td>\n",
       "      <td>49.3727</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>17.10223</td>\n",
       "      <td>588.460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>36</td>\n",
       "      <td>28.576676</td>\n",
       "      <td>86</td>\n",
       "      <td>4.345</td>\n",
       "      <td>0.921719</td>\n",
       "      <td>15.1248</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>9.15390</td>\n",
       "      <td>534.224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>34</td>\n",
       "      <td>31.975015</td>\n",
       "      <td>87</td>\n",
       "      <td>4.530</td>\n",
       "      <td>0.972138</td>\n",
       "      <td>28.7502</td>\n",
       "      <td>7.642760</td>\n",
       "      <td>5.62592</td>\n",
       "      <td>572.783</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>29</td>\n",
       "      <td>32.270788</td>\n",
       "      <td>84</td>\n",
       "      <td>5.810</td>\n",
       "      <td>1.203832</td>\n",
       "      <td>45.6196</td>\n",
       "      <td>6.209635</td>\n",
       "      <td>24.60330</td>\n",
       "      <td>904.981</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>35</td>\n",
       "      <td>30.276817</td>\n",
       "      <td>84</td>\n",
       "      <td>4.376</td>\n",
       "      <td>0.906707</td>\n",
       "      <td>39.2134</td>\n",
       "      <td>9.048185</td>\n",
       "      <td>16.43706</td>\n",
       "      <td>733.797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>54</td>\n",
       "      <td>30.483158</td>\n",
       "      <td>90</td>\n",
       "      <td>5.537</td>\n",
       "      <td>1.229214</td>\n",
       "      <td>12.3310</td>\n",
       "      <td>9.731380</td>\n",
       "      <td>10.19299</td>\n",
       "      <td>1227.910</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>45</td>\n",
       "      <td>37.035608</td>\n",
       "      <td>83</td>\n",
       "      <td>6.760</td>\n",
       "      <td>1.383997</td>\n",
       "      <td>39.9802</td>\n",
       "      <td>4.617125</td>\n",
       "      <td>8.70448</td>\n",
       "      <td>586.173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50</td>\n",
       "      <td>38.578759</td>\n",
       "      <td>106</td>\n",
       "      <td>6.703</td>\n",
       "      <td>1.752611</td>\n",
       "      <td>46.6401</td>\n",
       "      <td>4.667645</td>\n",
       "      <td>11.78388</td>\n",
       "      <td>887.160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>66</td>\n",
       "      <td>31.446541</td>\n",
       "      <td>90</td>\n",
       "      <td>9.245</td>\n",
       "      <td>2.052390</td>\n",
       "      <td>45.9624</td>\n",
       "      <td>10.355260</td>\n",
       "      <td>23.38190</td>\n",
       "      <td>1102.110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>35</td>\n",
       "      <td>35.250761</td>\n",
       "      <td>90</td>\n",
       "      <td>6.817</td>\n",
       "      <td>1.513374</td>\n",
       "      <td>50.6094</td>\n",
       "      <td>6.966895</td>\n",
       "      <td>22.03703</td>\n",
       "      <td>667.928</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>36</td>\n",
       "      <td>34.174890</td>\n",
       "      <td>80</td>\n",
       "      <td>6.590</td>\n",
       "      <td>1.300427</td>\n",
       "      <td>10.2809</td>\n",
       "      <td>5.065915</td>\n",
       "      <td>15.72187</td>\n",
       "      <td>581.313</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>48</td>\n",
       "      <td>28.125000</td>\n",
       "      <td>90</td>\n",
       "      <td>2.540</td>\n",
       "      <td>0.563880</td>\n",
       "      <td>15.5325</td>\n",
       "      <td>10.222310</td>\n",
       "      <td>16.11032</td>\n",
       "      <td>1698.440</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>85</td>\n",
       "      <td>27.688778</td>\n",
       "      <td>196</td>\n",
       "      <td>51.814</td>\n",
       "      <td>25.050342</td>\n",
       "      <td>70.8824</td>\n",
       "      <td>7.901685</td>\n",
       "      <td>55.21530</td>\n",
       "      <td>1078.359</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>48</td>\n",
       "      <td>31.250000</td>\n",
       "      <td>199</td>\n",
       "      <td>12.162</td>\n",
       "      <td>5.969920</td>\n",
       "      <td>18.1314</td>\n",
       "      <td>4.104105</td>\n",
       "      <td>53.63080</td>\n",
       "      <td>1698.440</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>58</td>\n",
       "      <td>29.154519</td>\n",
       "      <td>139</td>\n",
       "      <td>16.582</td>\n",
       "      <td>5.685415</td>\n",
       "      <td>22.8884</td>\n",
       "      <td>10.262660</td>\n",
       "      <td>13.97399</td>\n",
       "      <td>923.886</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>40</td>\n",
       "      <td>30.836531</td>\n",
       "      <td>128</td>\n",
       "      <td>41.894</td>\n",
       "      <td>13.227332</td>\n",
       "      <td>31.0385</td>\n",
       "      <td>6.160995</td>\n",
       "      <td>17.55503</td>\n",
       "      <td>638.261</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>82</td>\n",
       "      <td>31.217482</td>\n",
       "      <td>100</td>\n",
       "      <td>18.077</td>\n",
       "      <td>4.458993</td>\n",
       "      <td>31.6453</td>\n",
       "      <td>9.923650</td>\n",
       "      <td>19.94687</td>\n",
       "      <td>994.316</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>52</td>\n",
       "      <td>30.801249</td>\n",
       "      <td>87</td>\n",
       "      <td>30.212</td>\n",
       "      <td>6.483495</td>\n",
       "      <td>29.2739</td>\n",
       "      <td>6.268540</td>\n",
       "      <td>24.24591</td>\n",
       "      <td>764.667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>49</td>\n",
       "      <td>32.461911</td>\n",
       "      <td>134</td>\n",
       "      <td>24.887</td>\n",
       "      <td>8.225983</td>\n",
       "      <td>42.3914</td>\n",
       "      <td>10.793940</td>\n",
       "      <td>5.76800</td>\n",
       "      <td>656.393</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>60</td>\n",
       "      <td>31.231410</td>\n",
       "      <td>131</td>\n",
       "      <td>30.130</td>\n",
       "      <td>9.736007</td>\n",
       "      <td>37.8430</td>\n",
       "      <td>8.404430</td>\n",
       "      <td>11.50005</td>\n",
       "      <td>396.021</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>49</td>\n",
       "      <td>29.777778</td>\n",
       "      <td>70</td>\n",
       "      <td>8.396</td>\n",
       "      <td>1.449709</td>\n",
       "      <td>51.3387</td>\n",
       "      <td>10.731740</td>\n",
       "      <td>20.76801</td>\n",
       "      <td>602.486</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>44</td>\n",
       "      <td>27.887617</td>\n",
       "      <td>99</td>\n",
       "      <td>9.208</td>\n",
       "      <td>2.248594</td>\n",
       "      <td>12.6757</td>\n",
       "      <td>5.478170</td>\n",
       "      <td>23.03306</td>\n",
       "      <td>407.206</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>40</td>\n",
       "      <td>27.636054</td>\n",
       "      <td>103</td>\n",
       "      <td>2.432</td>\n",
       "      <td>0.617890</td>\n",
       "      <td>14.3224</td>\n",
       "      <td>6.783870</td>\n",
       "      <td>26.01360</td>\n",
       "      <td>293.123</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>71</td>\n",
       "      <td>27.915519</td>\n",
       "      <td>104</td>\n",
       "      <td>18.200</td>\n",
       "      <td>4.668907</td>\n",
       "      <td>53.4997</td>\n",
       "      <td>1.656020</td>\n",
       "      <td>49.24184</td>\n",
       "      <td>256.001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>69</td>\n",
       "      <td>28.444444</td>\n",
       "      <td>108</td>\n",
       "      <td>8.808</td>\n",
       "      <td>2.346451</td>\n",
       "      <td>14.7485</td>\n",
       "      <td>5.288025</td>\n",
       "      <td>16.48508</td>\n",
       "      <td>353.568</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>74</td>\n",
       "      <td>28.650138</td>\n",
       "      <td>88</td>\n",
       "      <td>3.012</td>\n",
       "      <td>0.653805</td>\n",
       "      <td>31.1233</td>\n",
       "      <td>7.652220</td>\n",
       "      <td>18.35574</td>\n",
       "      <td>572.401</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>66</td>\n",
       "      <td>26.562500</td>\n",
       "      <td>89</td>\n",
       "      <td>6.524</td>\n",
       "      <td>1.432235</td>\n",
       "      <td>14.9084</td>\n",
       "      <td>8.429960</td>\n",
       "      <td>14.91922</td>\n",
       "      <td>269.487</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>65</td>\n",
       "      <td>30.915577</td>\n",
       "      <td>97</td>\n",
       "      <td>10.491</td>\n",
       "      <td>2.510147</td>\n",
       "      <td>44.0217</td>\n",
       "      <td>3.710090</td>\n",
       "      <td>20.46850</td>\n",
       "      <td>396.648</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>72</td>\n",
       "      <td>29.136316</td>\n",
       "      <td>83</td>\n",
       "      <td>10.949</td>\n",
       "      <td>2.241625</td>\n",
       "      <td>26.8081</td>\n",
       "      <td>2.784910</td>\n",
       "      <td>14.76966</td>\n",
       "      <td>232.018</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>57</td>\n",
       "      <td>34.838148</td>\n",
       "      <td>95</td>\n",
       "      <td>12.548</td>\n",
       "      <td>2.940415</td>\n",
       "      <td>33.1612</td>\n",
       "      <td>2.364950</td>\n",
       "      <td>9.95420</td>\n",
       "      <td>655.834</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>73</td>\n",
       "      <td>37.109375</td>\n",
       "      <td>134</td>\n",
       "      <td>5.636</td>\n",
       "      <td>1.862886</td>\n",
       "      <td>41.4064</td>\n",
       "      <td>3.335665</td>\n",
       "      <td>6.89235</td>\n",
       "      <td>788.902</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>45</td>\n",
       "      <td>29.384757</td>\n",
       "      <td>90</td>\n",
       "      <td>4.713</td>\n",
       "      <td>1.046286</td>\n",
       "      <td>23.8479</td>\n",
       "      <td>6.644245</td>\n",
       "      <td>15.55625</td>\n",
       "      <td>621.273</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>46</td>\n",
       "      <td>33.180000</td>\n",
       "      <td>92</td>\n",
       "      <td>5.750</td>\n",
       "      <td>1.304867</td>\n",
       "      <td>18.6900</td>\n",
       "      <td>9.160000</td>\n",
       "      <td>8.89000</td>\n",
       "      <td>209.190</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>68</td>\n",
       "      <td>35.560000</td>\n",
       "      <td>131</td>\n",
       "      <td>8.150</td>\n",
       "      <td>2.633537</td>\n",
       "      <td>17.8700</td>\n",
       "      <td>11.900000</td>\n",
       "      <td>4.19000</td>\n",
       "      <td>198.400</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>75</td>\n",
       "      <td>30.480000</td>\n",
       "      <td>152</td>\n",
       "      <td>7.010</td>\n",
       "      <td>2.628283</td>\n",
       "      <td>50.5300</td>\n",
       "      <td>10.060000</td>\n",
       "      <td>11.73000</td>\n",
       "      <td>99.450</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>54</td>\n",
       "      <td>36.050000</td>\n",
       "      <td>119</td>\n",
       "      <td>11.910</td>\n",
       "      <td>3.495982</td>\n",
       "      <td>89.2700</td>\n",
       "      <td>8.010000</td>\n",
       "      <td>5.06000</td>\n",
       "      <td>218.280</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>45</td>\n",
       "      <td>26.850000</td>\n",
       "      <td>92</td>\n",
       "      <td>3.330</td>\n",
       "      <td>0.755688</td>\n",
       "      <td>54.6800</td>\n",
       "      <td>12.100000</td>\n",
       "      <td>10.96000</td>\n",
       "      <td>268.230</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>62</td>\n",
       "      <td>26.840000</td>\n",
       "      <td>100</td>\n",
       "      <td>4.530</td>\n",
       "      <td>1.117400</td>\n",
       "      <td>12.4500</td>\n",
       "      <td>21.420000</td>\n",
       "      <td>7.32000</td>\n",
       "      <td>330.160</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>65</td>\n",
       "      <td>32.050000</td>\n",
       "      <td>97</td>\n",
       "      <td>5.730</td>\n",
       "      <td>1.370998</td>\n",
       "      <td>61.4800</td>\n",
       "      <td>22.540000</td>\n",
       "      <td>10.33000</td>\n",
       "      <td>314.050</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>72</td>\n",
       "      <td>25.590000</td>\n",
       "      <td>82</td>\n",
       "      <td>2.820</td>\n",
       "      <td>0.570392</td>\n",
       "      <td>24.9600</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>3.27000</td>\n",
       "      <td>392.460</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>86</td>\n",
       "      <td>27.180000</td>\n",
       "      <td>138</td>\n",
       "      <td>19.910</td>\n",
       "      <td>6.777364</td>\n",
       "      <td>90.2800</td>\n",
       "      <td>14.110000</td>\n",
       "      <td>4.35000</td>\n",
       "      <td>90.090</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age        BMI  Glucose  Insulin       HOMA   Leptin  Adiponectin  \\\n",
       "0     48  23.500000       70    2.707   0.467409   8.8071     9.702400   \n",
       "1     83  20.690495       92    3.115   0.706897   8.8438     5.429285   \n",
       "2     82  23.124670       91    4.498   1.009651  17.9393    22.432040   \n",
       "3     68  21.367521       77    3.226   0.612725   9.8827     7.169560   \n",
       "4     86  21.111111       92    3.549   0.805386   6.6994     4.819240   \n",
       "5     49  22.854458       92    3.226   0.732087   6.8317    13.679750   \n",
       "6     89  22.700000       77    4.690   0.890787   6.9640     5.589865   \n",
       "7     76  23.800000      118    6.470   1.883201   4.3110    13.251320   \n",
       "8     73  22.000000       97    3.350   0.801543   4.4700    10.358725   \n",
       "9     75  23.000000       83    4.952   1.013839  17.1270    11.578990   \n",
       "10    34  21.470000       78    3.469   0.667436  14.5700    13.110000   \n",
       "11    29  23.010000       82    5.663   1.145436  35.5900    26.720000   \n",
       "12    25  22.860000       82    4.090   0.827271  20.4500    23.670000   \n",
       "13    24  18.670000       88    6.107   1.330000   8.8800    36.060000   \n",
       "14    38  23.340000       75    5.782   1.069670  15.2600    17.950000   \n",
       "15    44  20.760000       86    7.553   1.600000  14.0900    20.320000   \n",
       "16    47  22.030000       84    2.869   0.590000  26.6500    38.040000   \n",
       "17    61  32.038959       85   18.077   3.790144  30.7729     7.780255   \n",
       "18    64  34.529723       95    4.427   1.037394  21.2117     5.462620   \n",
       "19    32  36.512637       87   14.026   3.009980  49.3727     5.100000   \n",
       "20    36  28.576676       86    4.345   0.921719  15.1248     8.600000   \n",
       "21    34  31.975015       87    4.530   0.972138  28.7502     7.642760   \n",
       "22    29  32.270788       84    5.810   1.203832  45.6196     6.209635   \n",
       "23    35  30.276817       84    4.376   0.906707  39.2134     9.048185   \n",
       "24    54  30.483158       90    5.537   1.229214  12.3310     9.731380   \n",
       "25    45  37.035608       83    6.760   1.383997  39.9802     4.617125   \n",
       "26    50  38.578759      106    6.703   1.752611  46.6401     4.667645   \n",
       "27    66  31.446541       90    9.245   2.052390  45.9624    10.355260   \n",
       "28    35  35.250761       90    6.817   1.513374  50.6094     6.966895   \n",
       "29    36  34.174890       80    6.590   1.300427  10.2809     5.065915   \n",
       "..   ...        ...      ...      ...        ...      ...          ...   \n",
       "86    48  28.125000       90    2.540   0.563880  15.5325    10.222310   \n",
       "87    85  27.688778      196   51.814  25.050342  70.8824     7.901685   \n",
       "88    48  31.250000      199   12.162   5.969920  18.1314     4.104105   \n",
       "89    58  29.154519      139   16.582   5.685415  22.8884    10.262660   \n",
       "90    40  30.836531      128   41.894  13.227332  31.0385     6.160995   \n",
       "91    82  31.217482      100   18.077   4.458993  31.6453     9.923650   \n",
       "92    52  30.801249       87   30.212   6.483495  29.2739     6.268540   \n",
       "93    49  32.461911      134   24.887   8.225983  42.3914    10.793940   \n",
       "94    60  31.231410      131   30.130   9.736007  37.8430     8.404430   \n",
       "95    49  29.777778       70    8.396   1.449709  51.3387    10.731740   \n",
       "96    44  27.887617       99    9.208   2.248594  12.6757     5.478170   \n",
       "97    40  27.636054      103    2.432   0.617890  14.3224     6.783870   \n",
       "98    71  27.915519      104   18.200   4.668907  53.4997     1.656020   \n",
       "99    69  28.444444      108    8.808   2.346451  14.7485     5.288025   \n",
       "100   74  28.650138       88    3.012   0.653805  31.1233     7.652220   \n",
       "101   66  26.562500       89    6.524   1.432235  14.9084     8.429960   \n",
       "102   65  30.915577       97   10.491   2.510147  44.0217     3.710090   \n",
       "103   72  29.136316       83   10.949   2.241625  26.8081     2.784910   \n",
       "104   57  34.838148       95   12.548   2.940415  33.1612     2.364950   \n",
       "105   73  37.109375      134    5.636   1.862886  41.4064     3.335665   \n",
       "106   45  29.384757       90    4.713   1.046286  23.8479     6.644245   \n",
       "107   46  33.180000       92    5.750   1.304867  18.6900     9.160000   \n",
       "108   68  35.560000      131    8.150   2.633537  17.8700    11.900000   \n",
       "109   75  30.480000      152    7.010   2.628283  50.5300    10.060000   \n",
       "110   54  36.050000      119   11.910   3.495982  89.2700     8.010000   \n",
       "111   45  26.850000       92    3.330   0.755688  54.6800    12.100000   \n",
       "112   62  26.840000      100    4.530   1.117400  12.4500    21.420000   \n",
       "113   65  32.050000       97    5.730   1.370998  61.4800    22.540000   \n",
       "114   72  25.590000       82    2.820   0.570392  24.9600    33.750000   \n",
       "115   86  27.180000      138   19.910   6.777364  90.2800    14.110000   \n",
       "\n",
       "     Resistin     MCP.1  Classification  \n",
       "0     7.99585   417.114               1  \n",
       "1     4.06405   468.786               1  \n",
       "2     9.27715   554.697               1  \n",
       "3    12.76600   928.220               1  \n",
       "4    10.57635   773.920               1  \n",
       "5    10.31760   530.410               1  \n",
       "6    12.93610  1256.083               1  \n",
       "7     5.10420   280.694               1  \n",
       "8     6.28445   136.855               1  \n",
       "9     7.09130   318.302               1  \n",
       "10    6.92000   354.600               1  \n",
       "11    4.58000   174.800               1  \n",
       "12    5.14000   313.730               1  \n",
       "13    6.85000   632.220               1  \n",
       "14    9.35000   165.020               1  \n",
       "15    7.64000    63.610               1  \n",
       "16    3.32000   191.720               1  \n",
       "17   13.68392   444.395               1  \n",
       "18    6.70188   252.449               1  \n",
       "19   17.10223   588.460               1  \n",
       "20    9.15390   534.224               1  \n",
       "21    5.62592   572.783               1  \n",
       "22   24.60330   904.981               1  \n",
       "23   16.43706   733.797               1  \n",
       "24   10.19299  1227.910               1  \n",
       "25    8.70448   586.173               1  \n",
       "26   11.78388   887.160               1  \n",
       "27   23.38190  1102.110               1  \n",
       "28   22.03703   667.928               1  \n",
       "29   15.72187   581.313               1  \n",
       "..        ...       ...             ...  \n",
       "86   16.11032  1698.440               2  \n",
       "87   55.21530  1078.359               2  \n",
       "88   53.63080  1698.440               2  \n",
       "89   13.97399   923.886               2  \n",
       "90   17.55503   638.261               2  \n",
       "91   19.94687   994.316               2  \n",
       "92   24.24591   764.667               2  \n",
       "93    5.76800   656.393               2  \n",
       "94   11.50005   396.021               2  \n",
       "95   20.76801   602.486               2  \n",
       "96   23.03306   407.206               2  \n",
       "97   26.01360   293.123               2  \n",
       "98   49.24184   256.001               2  \n",
       "99   16.48508   353.568               2  \n",
       "100  18.35574   572.401               2  \n",
       "101  14.91922   269.487               2  \n",
       "102  20.46850   396.648               2  \n",
       "103  14.76966   232.018               2  \n",
       "104   9.95420   655.834               2  \n",
       "105   6.89235   788.902               2  \n",
       "106  15.55625   621.273               2  \n",
       "107   8.89000   209.190               2  \n",
       "108   4.19000   198.400               2  \n",
       "109  11.73000    99.450               2  \n",
       "110   5.06000   218.280               2  \n",
       "111  10.96000   268.230               2  \n",
       "112   7.32000   330.160               2  \n",
       "113  10.33000   314.050               2  \n",
       "114   3.27000   392.460               2  \n",
       "115   4.35000    90.090               2  \n",
       "\n",
       "[116 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srcData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# scaledData = \n",
    "\n",
    "# split the dataset into feature set and response variable (Classification)\n",
    "X = srcData.drop('Classification', axis='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>HOMA</th>\n",
       "      <th>Leptin</th>\n",
       "      <th>Adiponectin</th>\n",
       "      <th>Resistin</th>\n",
       "      <th>MCP.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>70</td>\n",
       "      <td>2.707</td>\n",
       "      <td>0.467409</td>\n",
       "      <td>8.8071</td>\n",
       "      <td>9.702400</td>\n",
       "      <td>7.99585</td>\n",
       "      <td>417.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>20.690495</td>\n",
       "      <td>92</td>\n",
       "      <td>3.115</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>8.8438</td>\n",
       "      <td>5.429285</td>\n",
       "      <td>4.06405</td>\n",
       "      <td>468.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>23.124670</td>\n",
       "      <td>91</td>\n",
       "      <td>4.498</td>\n",
       "      <td>1.009651</td>\n",
       "      <td>17.9393</td>\n",
       "      <td>22.432040</td>\n",
       "      <td>9.27715</td>\n",
       "      <td>554.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68</td>\n",
       "      <td>21.367521</td>\n",
       "      <td>77</td>\n",
       "      <td>3.226</td>\n",
       "      <td>0.612725</td>\n",
       "      <td>9.8827</td>\n",
       "      <td>7.169560</td>\n",
       "      <td>12.76600</td>\n",
       "      <td>928.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "      <td>21.111111</td>\n",
       "      <td>92</td>\n",
       "      <td>3.549</td>\n",
       "      <td>0.805386</td>\n",
       "      <td>6.6994</td>\n",
       "      <td>4.819240</td>\n",
       "      <td>10.57635</td>\n",
       "      <td>773.920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age        BMI  Glucose  Insulin      HOMA   Leptin  Adiponectin  Resistin  \\\n",
       "0   48  23.500000       70    2.707  0.467409   8.8071     9.702400   7.99585   \n",
       "1   83  20.690495       92    3.115  0.706897   8.8438     5.429285   4.06405   \n",
       "2   82  23.124670       91    4.498  1.009651  17.9393    22.432040   9.27715   \n",
       "3   68  21.367521       77    3.226  0.612725   9.8827     7.169560  12.76600   \n",
       "4   86  21.111111       92    3.549  0.805386   6.6994     4.819240  10.57635   \n",
       "\n",
       "     MCP.1  \n",
       "0  417.114  \n",
       "1  468.786  \n",
       "2  554.697  \n",
       "3  928.220  \n",
       "4  773.920  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srcData.head()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(srcData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = srcData['Classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "(116, 9)\n",
      "(116,)\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(type(y))\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age        BMI  Glucose  Insulin      HOMA   Leptin  Adiponectin  Resistin  \\\n",
      "0   48  23.500000       70    2.707  0.467409   8.8071     9.702400   7.99585   \n",
      "1   83  20.690495       92    3.115  0.706897   8.8438     5.429285   4.06405   \n",
      "2   82  23.124670       91    4.498  1.009651  17.9393    22.432040   9.27715   \n",
      "3   68  21.367521       77    3.226  0.612725   9.8827     7.169560  12.76600   \n",
      "4   86  21.111111       92    3.549  0.805386   6.6994     4.819240  10.57635   \n",
      "\n",
      "     MCP.1  \n",
      "0  417.114  \n",
      "1  468.786  \n",
      "2  554.697  \n",
      "3  928.220  \n",
      "4  773.920  \n",
      "--------------------\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: Classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.head())\n",
    "print('--------------------')\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the feature set data using StandardScaler alone\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# X_scld = scaler.fit(X)\n",
    "# way to restore the column headers to a scaled feature set dataframe\n",
    "X_scld = pd.DataFrame(scaler.fit_transform(X), columns=list(X.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>HOMA</th>\n",
       "      <th>Leptin</th>\n",
       "      <th>Adiponectin</th>\n",
       "      <th>Resistin</th>\n",
       "      <th>MCP.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.579794</td>\n",
       "      <td>-0.816675</td>\n",
       "      <td>-1.239222</td>\n",
       "      <td>-0.728739</td>\n",
       "      <td>-0.614282</td>\n",
       "      <td>-0.932334</td>\n",
       "      <td>-0.070222</td>\n",
       "      <td>-0.545517</td>\n",
       "      <td>-0.341251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.601821</td>\n",
       "      <td>-1.378751</td>\n",
       "      <td>-0.258299</td>\n",
       "      <td>-0.688038</td>\n",
       "      <td>-0.548240</td>\n",
       "      <td>-0.930413</td>\n",
       "      <td>-0.697350</td>\n",
       "      <td>-0.864214</td>\n",
       "      <td>-0.191224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.539489</td>\n",
       "      <td>-0.891764</td>\n",
       "      <td>-0.302887</td>\n",
       "      <td>-0.550073</td>\n",
       "      <td>-0.464752</td>\n",
       "      <td>-0.454219</td>\n",
       "      <td>1.797998</td>\n",
       "      <td>-0.441660</td>\n",
       "      <td>0.058214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666843</td>\n",
       "      <td>-1.243303</td>\n",
       "      <td>-0.927110</td>\n",
       "      <td>-0.676965</td>\n",
       "      <td>-0.574210</td>\n",
       "      <td>-0.876021</td>\n",
       "      <td>-0.441945</td>\n",
       "      <td>-0.158867</td>\n",
       "      <td>1.142718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.788816</td>\n",
       "      <td>-1.294601</td>\n",
       "      <td>-0.258299</td>\n",
       "      <td>-0.644743</td>\n",
       "      <td>-0.521081</td>\n",
       "      <td>-1.042682</td>\n",
       "      <td>-0.786881</td>\n",
       "      <td>-0.336352</td>\n",
       "      <td>0.694716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age       BMI   Glucose   Insulin      HOMA    Leptin  Adiponectin  \\\n",
       "0 -0.579794 -0.816675 -1.239222 -0.728739 -0.614282 -0.932334    -0.070222   \n",
       "1  1.601821 -1.378751 -0.258299 -0.688038 -0.548240 -0.930413    -0.697350   \n",
       "2  1.539489 -0.891764 -0.302887 -0.550073 -0.464752 -0.454219     1.797998   \n",
       "3  0.666843 -1.243303 -0.927110 -0.676965 -0.574210 -0.876021    -0.441945   \n",
       "4  1.788816 -1.294601 -0.258299 -0.644743 -0.521081 -1.042682    -0.786881   \n",
       "\n",
       "   Resistin     MCP.1  \n",
       "0 -0.545517 -0.341251  \n",
       "1 -0.864214 -0.191224  \n",
       "2 -0.441660  0.058214  \n",
       "3 -0.158867  1.142718  \n",
       "4 -0.336352  0.694716  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scld.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scld.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the X and y sets into training and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scld, y, random_state=0, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87, 9)\n",
      "(29, 9)\n",
      "(87,)\n",
      "(29,)\n",
      "------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print('------------------------')\n",
    "\n",
    "print(type(X_train))\n",
    "print(type(X_test))\n",
    "print(type(y_train))\n",
    "print(type(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Series.unique of 0     -0.579794\n",
      "1      1.601821\n",
      "2      1.539489\n",
      "3      0.666843\n",
      "4      1.788816\n",
      "5     -0.517462\n",
      "6      1.975812\n",
      "7      1.165498\n",
      "8      0.978503\n",
      "9      1.103166\n",
      "10    -1.452439\n",
      "11    -1.764099\n",
      "12    -2.013426\n",
      "13    -2.075758\n",
      "14    -1.203112\n",
      "15    -0.829121\n",
      "16    -0.642125\n",
      "17     0.230520\n",
      "18     0.417516\n",
      "19    -1.577103\n",
      "20    -1.327776\n",
      "21    -1.452439\n",
      "22    -1.764099\n",
      "23    -1.390108\n",
      "24    -0.205803\n",
      "25    -0.766789\n",
      "26    -0.455130\n",
      "27     0.542180\n",
      "28    -1.390108\n",
      "29    -1.327776\n",
      "         ...   \n",
      "86    -0.579794\n",
      "87     1.726485\n",
      "88    -0.579794\n",
      "89     0.043525\n",
      "90    -1.078448\n",
      "91     1.539489\n",
      "92    -0.330466\n",
      "93    -0.517462\n",
      "94     0.168189\n",
      "95    -0.517462\n",
      "96    -0.829121\n",
      "97    -1.078448\n",
      "98     0.853839\n",
      "99     0.729175\n",
      "100    1.040834\n",
      "101    0.542180\n",
      "102    0.479848\n",
      "103    0.916171\n",
      "104   -0.018807\n",
      "105    0.978503\n",
      "106   -0.766789\n",
      "107   -0.704457\n",
      "108    0.666843\n",
      "109    1.103166\n",
      "110   -0.205803\n",
      "111   -0.766789\n",
      "112    0.292852\n",
      "113    0.479848\n",
      "114    0.916171\n",
      "115    1.788816\n",
      "Name: Age, Length: 116, dtype: float64>\n"
     ]
    }
   ],
   "source": [
    "# calculate the naive evaluation parameters. Predicting everything to the true\n",
    "\n",
    "#unique classes\n",
    "# print(y_train.unique)\n",
    "print(X_scld['Age'].unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicts everything to be classified as 1 or True\n",
    "y_pred = [1]*len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:  0.41379310344827586\n",
      "\n",
      "Precision:  1.0\n",
      "\n",
      "Recall:  0.41379310344827586\n",
      "\n",
      "F1Score:  0.5853658536585366\n",
      "\n",
      "Confusion Matrix: \n",
      " [[12 17]\n",
      " [ 0  0]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.41      0.59        29\n",
      "          2       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.41      0.59        29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anshul/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print('\\nAccuracy: ', accuracy)\n",
    "\n",
    "precision = precision_score(y_pred, y_test)\n",
    "print('\\nPrecision: ', precision)\n",
    "\n",
    "recall = recall_score(y_pred, y_test)\n",
    "print('\\nRecall: ', recall)\n",
    "\n",
    "f1Score = f1_score(y_pred, y_test)\n",
    "print('\\nF1Score: ', f1Score)\n",
    "\n",
    "conf_matr = confusion_matrix(y_pred, y_test)\n",
    "print('\\nConfusion Matrix: \\n', conf_matr)\n",
    "\n",
    "class_rept = classification_report(y_pred, y_test)\n",
    "print('\\nClassification Report: \\n', class_rept)\n",
    "\n",
    "# confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "## !! Logistic Regression !!##\n",
    "##############################\n",
    "\n",
    "# fitting Logistic Regression to the data\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logReg = LogisticRegression()\n",
    "logReg.fit(X_train, y_train)\n",
    "y_pred = logReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:  0.5862068965517241\n",
      "\n",
      "Precision:  0.4166666666666667\n",
      "\n",
      "Recall:  0.5\n",
      "\n",
      "F1Score:  0.45454545454545453\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 5  5]\n",
      " [ 7 12]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.50      0.45        10\n",
      "          2       0.71      0.63      0.67        19\n",
      "\n",
      "avg / total       0.61      0.59      0.59        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# implementing evaluation parameters on the predicted values\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print('\\nAccuracy: ', accuracy)\n",
    "\n",
    "precision = precision_score(y_pred, y_test)\n",
    "print('\\nPrecision: ', precision)\n",
    "\n",
    "recall = recall_score(y_pred, y_test)\n",
    "print('\\nRecall: ', recall)\n",
    "\n",
    "f1Score = f1_score(y_pred, y_test)\n",
    "print('\\nF1Score: ', f1Score)\n",
    "\n",
    "conf_matr = confusion_matrix(y_pred, y_test)\n",
    "print('\\nConfusion Matrix: \\n', conf_matr)\n",
    "\n",
    "class_rept = classification_report(y_pred, y_test)\n",
    "print('\\nClassification Report: \\n', class_rept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################\n",
    "## !! Logistic Regression with 5 fold cross validation !!##\n",
    "###########################################################\n",
    "\n",
    "#  implementing LogisticRegression with 5 folds cross validation\n",
    "# from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossVal = cross_validate(logReg, X, y, scoring='accuracy', cv=5)\n",
    "crossVal = cross_val_score(logReg, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58333333 0.625      0.69565217 0.69565217 0.5       ]\n"
     ]
    }
   ],
   "source": [
    "print(crossVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6199275362318841"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average accuracy\n",
    "crossVal.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############\n",
    "## !! KNN !!##\n",
    "##############\n",
    "\n",
    "# implementing KNN for k=3\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:  0.7586206896551724\n",
      "\n",
      "Precision:  0.8333333333333334\n",
      "\n",
      "Recall:  0.6666666666666666\n",
      "\n",
      "F1Score:  0.7407407407407408\n",
      "\n",
      "Confusion Matrix: \n",
      " [[10  5]\n",
      " [ 2 12]]\n",
      "\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.83      0.67      0.74        15\n",
      "          2       0.71      0.86      0.77        14\n",
      "\n",
      "avg / total       0.77      0.76      0.76        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# implementing evaluation parameters on the predicted values\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print('\\nAccuracy: ', accuracy)\n",
    "\n",
    "precision = precision_score(y_pred, y_test)\n",
    "print('\\nPrecision: ', precision)\n",
    "\n",
    "recall = recall_score(y_pred, y_test)\n",
    "print('\\nRecall: ', recall)\n",
    "\n",
    "f1Score = f1_score(y_pred, y_test)\n",
    "print('\\nF1Score: ', f1Score)\n",
    "\n",
    "conf_matr = confusion_matrix(y_pred, y_test)\n",
    "print('\\nConfusion Matrix: \\n', conf_matr)\n",
    "\n",
    "class_rept = classification_report(y_pred, y_test)\n",
    "print('\\nClassification Report: \\n', class_rept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing for multiple values of k to find the best k value - one with highest accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder for the accuracy values\n",
    "accuracy = []\n",
    "\n",
    "# define a range for k values 1 - 25\n",
    "k_range = range(1, 26)\n",
    "# accuracy = [0.00]*len(list(k_range))\n",
    "# print(list(k_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# calculate the accuracy for various k values\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    accuracy.append(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Testing Accuracy')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the relationship between k and accuracy scores\n",
    "plt.plot(k_range, accuracy)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Testing Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy is the heighest for k = 3, 4, 5, 7, 8 - 0.7586206896551724"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy:  0.7586206896551724\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=8)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print('\\nAccuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
